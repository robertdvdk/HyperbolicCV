# python code/classification/train.py -c classification/config/L-ResNet18.txt

# Output settings
exp_name = L-ResNet18_our_linear_good_hyperparams_enc_k_1
output_dir = classification/output

# General settings
device = cuda:0
dtype = float32
seed = 1
# load_checkpoint = classification/output/best_L-ResNet18_our_linear.pth

# General training hyperparameters
num_epochs = 200
batch_size = 128
lr = 2e-2
weight_decay = 5e-3
optimizer = RiemannianSGD
use_lr_scheduler = True
warmup_epochs = 10

# General validation/testing hyperparameters
batch_size_test = 128

# Model selection
num_layers = 18
embedding_dim = 512
encoder_manifold = lorentz
decoder_manifold = lorentz

# Manifold settings
# learn_k = True
encoder_k = 1.0
decoder_k = 1.0

# Dataset settings
dataset = CIFAR-100 # CIFAR-10 or Tiny-ImageNet
train_subset_fraction = 1.0
val_fraction = 0.1